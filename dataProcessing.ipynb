{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,time,re,json\n",
    "from glob import glob\n",
    "import datetime\n",
    "import sqlite3\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=os.path.join('..','data','phase-01','data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tile Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TILE:\n",
    "    def __init__(self, filepath):\n",
    "        img = cv2.imread(filepath)\n",
    "        self.array = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.shape = self.array.shape\n",
    "        msk_img = cv2.imread(re.findall('^.*sentinel.*?/', file)[0]+'masks/sugarcane-region-mask.png')\n",
    "        self.mask = cv2.cvtColor(msk_img, cv2.COLOR_BGR2RGB)\n",
    "    def image(self):\n",
    "        plt.figure(figsize=(8,8))\n",
    "        self.image = plt.imshow(self.array)\n",
    "    def detect_harvested(self):\n",
    "        setTime = time.time()\n",
    "        plt.figure(figsize=(8,8))\n",
    "        pixels = self.array.copy()\n",
    "        mask = self.mask\n",
    "        x = pixels.reshape(512**2, 3)\n",
    "        x = pd.DataFrame(x, columns=['r','g','b'])\n",
    "        mask = pd.DataFrame(mask.reshape(512**2, 3), index = x.index)\n",
    "        mask_idx = mask[~(mask.sum(axis=1)==0)].index\n",
    "        x.loc[mask_idx, 'r'] = 0\n",
    "        x.loc[mask_idx, 'g'] = 0\n",
    "        x.loc[mask_idx, 'b'] = 0\n",
    "        idx = x[x.g/(x.sum(axis=1)) < 0.335].index.difference(mask_idx)\n",
    "        x.loc[idx, 'r'] = 255\n",
    "        x.loc[idx, 'g'] = 0\n",
    "        x.loc[idx, 'b'] = 0\n",
    "        x = x.values.reshape(512,512,3)\n",
    "        self.area = 100*(len(idx)/1000)\n",
    "        pixels = np.array([0,0,255]*512**2).reshape(512,512,3)\n",
    "        return plt.imshow(x)\n",
    "    def harvested_area(self):\n",
    "        if 'self.area' not in locals():\n",
    "            pixels = self.array.copy()\n",
    "            mask = self.mask\n",
    "            width, height, _ = pixels.shape\n",
    "            x = pixels.reshape(512**2, 3)\n",
    "            x = pd.DataFrame(x, columns=['r','g','b'])\n",
    "            mask = pd.DataFrame(mask.reshape(512**2, 3), index = x.index)\n",
    "            mask_idx = mask[~(mask.sum(axis=1)==0)].index\n",
    "            idx = x[x.g/(x.sum(axis=1)) < 0.335].index\n",
    "            self.area = 100*(len(idx.difference(mask_idx))/1000)\n",
    "        return self.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Process timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTimestamp(root,source,files):\n",
    "    #Iterate all image files\n",
    "    data=dict()\n",
    "    cols=['tile_x','tile_y','imgtype','year','month','day']\n",
    "    for file in files:\n",
    "        if not '.png' in file: continue\n",
    "        #Split timestamp\n",
    "        name=file.rsplit('.',1)[0]\n",
    "        data[name]=name.split('-')\n",
    "        \n",
    "    #Create dataframe    \n",
    "    df=pd.DataFrame().from_dict(data,orient='index',columns=cols)\n",
    "    df=df.reset_index().rename({'index':'File'},axis=1)\n",
    "    \n",
    "    #Add date\n",
    "    df['date']=df.apply(lambda x: datetime.date(int(x['year']), int(x['month']), int(x['day'])), axis=1)\n",
    "    \n",
    "    return df\n",
    "     \n",
    "def processTimeseriesByDate(root,source,files):\n",
    "    \n",
    "    cnt=0\n",
    "    \n",
    "    #Timestamp process\n",
    "    df_timestamps=processTimestamp(root,source,files)\n",
    "    \n",
    "    #Iterate all dates\n",
    "    for date in df_timestamps['date'].unique():\n",
    "        df=pd.DataFrame()\n",
    "        t0=time.time()\n",
    "        imgfiles=df_timestamps.loc[df_timestamps['date']==date,['File','imgtype']].values\n",
    "        print(time.time()-t0)\n",
    "        for imgfile in imgfiles:\n",
    "            print('>>>>>')\n",
    "            #Extract pixel data\n",
    "            rgb=cv2.cvtColor(cv2.imread(os.path.join(root,imgfile[0]+'.png')), cv2.COLOR_BGR2RGB)\n",
    "            t0=time.time()\n",
    "            \n",
    "            print('------')\n",
    "            #Create frame\n",
    "            colIndex=pd.MultiIndex.from_arrays([[imgfile[1],imgfile[1],imgfile[1]], ['r','g','b']], names=('imgtype', 'rgb'))\n",
    "            data=pd.DataFrame(rgb.reshape(len(rgb[0])**2, 3),columns=colIndex)\n",
    "            print(time.time()-t0)\n",
    "            t0=time.time()\n",
    "\n",
    "            #Append data\n",
    "            df=data if df.empty else df.merge(data,left_index=True,right_index=True)\n",
    "            print(time.time()-t0)\n",
    "            t0=time.time()\n",
    "        \n",
    "        #Index\n",
    "        df.index.name='Pixel'\n",
    "        #temp.index=pd.MultiIndex.from_arrays([[imgfile[0] for _ in range(len(temp))], [i for i in range(len(temp))]], names=('File', 'Pixel'))\n",
    "        #df=temp if df.empty else df.append(temp)\n",
    "        \n",
    "        print(time.time()-t0)\n",
    "        t0=time.time()\n",
    "        #Output image data\n",
    "        imgpath=os.path.join(parsedpath,'timeseries')\n",
    "        if not os.path.exists(imgpath):\n",
    "            os.makedirs(imgpath)\n",
    "        df.to_csv(os.path.join(imgpath,date.strftime(\"%Y-%m-%d\")+'.csv'))\n",
    "             \n",
    "        print(time.time()-t0)\n",
    "        \n",
    "        if cnt%20==0:\n",
    "            print(cnt)\n",
    "            break\n",
    "        cnt+=1\n",
    "        \n",
    "    return None\n",
    "\n",
    "\n",
    "def processTimeseriesByPixel(root,source,files):\n",
    "    \n",
    "    cnt=0\n",
    "    \n",
    "    #Timestamp process\n",
    "    df_timestamps=processTimestamp(root,source,files)\n",
    "\n",
    "    ts=time.time()\n",
    "    #Iterate all dates\n",
    "    df_full=pd.DataFrame()\n",
    "    for date in df_timestamps['date'].unique():\n",
    "        df=pd.DataFrame()\n",
    "        imgfiles=df_timestamps.loc[df_timestamps['date']==date,['File','imgtype']].values\n",
    "        for imgfile in imgfiles:\n",
    "            \n",
    "            #Extract pixel data\n",
    "            rgb=cv2.cvtColor(cv2.imread(os.path.join(root,imgfile[0]+'.png')), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            #Create frame\n",
    "            colIndex=pd.MultiIndex.from_arrays([[imgfile[1],imgfile[1],imgfile[1]], ['r','g','b']], names=('imgtype', 'rgb'))\n",
    "            data=pd.DataFrame(rgb.reshape(len(rgb[0])**2, 3),columns=colIndex)\n",
    "            \n",
    "            #Append data\n",
    "            df=data if df.empty else df.merge(data,left_index=True,right_index=True)\n",
    "        \n",
    "        #Add in more features!!!!\n",
    "        #df['Harvested']=df.apply(lambda x: getHarvestState(x), axis=1)\n",
    "        \n",
    "        #Set indexes\n",
    "        df.index.name='Pixel'\n",
    "        df['Date'] = date\n",
    "        df.set_index('Date', append=True, inplace=True)\n",
    "        \n",
    "        #Append data\n",
    "        df_full=df if df_full.empty else df_full.append(df)\n",
    "        print(df_full.shape)\n",
    "        \n",
    "        if cnt%20==0:\n",
    "            print(cnt)\n",
    "            #break\n",
    "        cnt+=1\n",
    "        \n",
    "    print(time.time()-ts)\n",
    "\n",
    "    if(0):\n",
    "        t0=time.time()\n",
    "        #Output image data\n",
    "        imgpath=os.path.join(parsedpath,'timeseries')\n",
    "        if not os.path.exists(imgpath):\n",
    "            os.makedirs(imgpath)\n",
    "        df_full.to_hdf(os.path.join(imgpath,'data.csv'), 'data', mode='w')\n",
    "        #df_full.to_csv(os.path.join(imgpath,date.strftime(\"%Y-%m-%d\")+'.csv'))\n",
    "        print(time.time()-t0)\n",
    "        \n",
    "    return df_full\n",
    "\n",
    "def createSQL(df):\n",
    "    \n",
    "    t0=time.time()\n",
    "    #Output image data\n",
    "    table_name='images'\n",
    "    dbpath=os.path.join(parsedpath,'timeseries.db')\n",
    "    if not os.path.exists(dbpath):\n",
    "        open(dbpath,'w').close()\n",
    "    conn = sqlite3.connect(dbpath)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    #Create sql\n",
    "    sql='DROP TABLE IF EXISTS '+table_name\n",
    "    c.execute(sql)\n",
    "    conn.commit()\n",
    "    \n",
    "    #Columns in sql\n",
    "    sqlCols=''\n",
    "    for col in df:\n",
    "        dtype='INTEGER' if 'int' in str(df[col].dtypes) else 'CHAR(32)'\n",
    "        sqlCols+=col+' '+dtype+','\n",
    "    sql='CREATE TABLE '+table_name+' ('+sqlCols[:-1]+');'\n",
    "    c.execute(sql)\n",
    "    conn.commit()\n",
    "\n",
    "    #Insert sql\n",
    "    inserts=[]\n",
    "    for i in range(len(df)):\n",
    "        sql='INSERT INTO '+table_name+' (' + ','.join([col for col in df]) + ') '\n",
    "        sql+='VALUES(' + ','.join(['?' for _ in df]) + ')'\n",
    "        inserts.append(tuple(val for val in list(df.iloc[i].values)))\n",
    "        \n",
    "    #Execute statement\n",
    "    c.executemany(sql,inserts)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    print(time.time()-t0)\n",
    "    \n",
    "def processTimeseriesByPixel2(root,source,files):\n",
    "    \n",
    "    cnt=0\n",
    "    \n",
    "    #Timestamp process\n",
    "    df_timestamps=processTimestamp(root,source,files)\n",
    "\n",
    "    ts=time.time()\n",
    "    #Iterate all dates\n",
    "    df_full=pd.DataFrame()\n",
    "    for date in df_timestamps['date'].unique():\n",
    "        df=pd.DataFrame()\n",
    "        imgfiles=df_timestamps.loc[df_timestamps['date']==date,['File','imgtype']].values\n",
    "        for imgfile in imgfiles:\n",
    "            \n",
    "            #Extract pixel data\n",
    "            rgb=cv2.cvtColor(cv2.imread(os.path.join(root,imgfile[0]+'.png')), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            #Create frame\n",
    "            data=pd.DataFrame(rgb.reshape(len(rgb[0])**2, 3),columns=['r_'+imgfile[1],'g_'+imgfile[1],'b_'+imgfile[1]])\n",
    "            \n",
    "            #Append data\n",
    "            df=data if df.empty else df.merge(data,left_index=True,right_index=True)\n",
    "        \n",
    "        #Set indexes\n",
    "        df=df.reset_index().rename({'index':'Pixel'},axis=1)\n",
    "        df['Date'] = date\n",
    "        \n",
    "        #Append data\n",
    "        df_full=df if df_full.empty else df_full.append(df)\n",
    "        print(df_full.shape)\n",
    "        \n",
    "        if cnt%20==5:\n",
    "            print(cnt)\n",
    "            break\n",
    "        cnt+=1\n",
    "        \n",
    "    print(time.time()-ts)\n",
    "    createSQL(df_full)\n",
    "        \n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Process geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processGeometry(root,source,files):\n",
    "    \n",
    "    #Iterate all geojson files\n",
    "    df=pd.DataFrame()\n",
    "    data=dict()\n",
    "    for file in files:\n",
    "        if not '.geojson' in file: continue\n",
    "        #Split timestamp\n",
    "        name=file.rsplit('.',1)[0]\n",
    "        tile=[''.join(re.findall(r'\\d+', s)) for s in name.split('-')[1:]]\n",
    "        data[name]=dict()\n",
    "        data[name]['tile_x']=tile[0]\n",
    "        data[name]['tile_y']=tile[1]\n",
    "        \n",
    "        #Read geojson\n",
    "        with open(os.path.join(root,file),'r') as f:\n",
    "            geo=json.load(f)\n",
    "        \n",
    "        #Extract crs\n",
    "        data[name]['crs']=geo['crs']['properties']['name']\n",
    "        \n",
    "        #Extract coordinates\n",
    "        for i,coord in enumerate(geo['features'][0]['geometry']['coordinates'][0]):\n",
    "            data[name]['lat'+str(i)]=coord[1]\n",
    "            data[name]['lon'+str(i)]=coord[0]\n",
    "    \n",
    "        #Append data\n",
    "        data=pd.DataFrame().from_dict(data,orient='index')\n",
    "        df=data if df.empty else df.append(data)\n",
    "                    \n",
    "    return df.reset_index().rename({'index':'Geojson'},axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Process masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processMasks(root,source,files):\n",
    "    \n",
    "    #Iterate all masks\n",
    "    cols=['r','g','b']\n",
    "    df=pd.DataFrame()\n",
    "    for file in files:\n",
    "        if not '.png' in file: continue\n",
    "        \n",
    "        #Extract pixel data\n",
    "        rgb=cv2.cvtColor(cv2.imread(os.path.join(root,file)), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #Create frame\n",
    "        data=pd.DataFrame(rgb.reshape(len(rgb[0])**2, 3),columns=cols)\n",
    "        data['Mask']=file.rsplit('.',1)[0]\n",
    "        \n",
    "        #Append data\n",
    "        df=data if df.empty else df.append(data)\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Process metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processMetadata(root,source,files):\n",
    "    \n",
    "    #Iterate all metadata\n",
    "    df=pd.DataFrame()\n",
    "    cols=['year','month','day']\n",
    "    for file in files:\n",
    "        data=dict()\n",
    "        if not '.json' in file: continue\n",
    "        #Split timestamp\n",
    "        name=file.rsplit('.',1)[0]\n",
    "        date=name.split('-')\n",
    "        data[name]=dict()\n",
    "        data[name]['year']=date[0]\n",
    "        data[name]['month']=date[1]\n",
    "        data[name]['day']=date[2]\n",
    "        \n",
    "        #Read geojson\n",
    "        with open(os.path.join(root,file),'r') as f:\n",
    "            metadata=json.load(f)['metadata']\n",
    "        \n",
    "        #Metrics\n",
    "        inds=['collection','processingLevel','platform','instrument','resolution','sensorMode','orbitNumber','snowCover','cloudCover']\n",
    "        for ind in inds:\n",
    "            data[name][ind]=metadata[ind]\n",
    "        \n",
    "        #Add centroid\n",
    "        data[name]['lat_centroid']=metadata['centroid']['coordinates'][1]\n",
    "        data[name]['lon_centroid']=metadata['centroid']['coordinates'][0]\n",
    "        \n",
    "        #Append data\n",
    "        data=pd.DataFrame().from_dict(data,orient='index')\n",
    "        df=data if df.empty else df.append(data)\n",
    "                    \n",
    "    return df.reset_index().rename({'index':'Metadata'},axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Walk path\n",
    "#startdate=datetime.date(2016, 1, 1)\n",
    "#enddate=datetime.date(2017, 1, 1)\n",
    "for root, dirs, files in os.walk(PATH,topdown=True):\n",
    "    \n",
    "    #Parsed directory\n",
    "    tile=os.path.split(os.path.split(root)[0])[1]\n",
    "    if 'tile' not in tile: continue\n",
    "    parsedpath=os.path.join(os.path.split(PATH)[0],'parsed',tile)\n",
    "    if not os.path.exists(parsedpath):\n",
    "        os.makedirs(parsedpath)\n",
    "        \n",
    "    #Source types\n",
    "    source=os.path.split(root)[-1]\n",
    "    if source=='timeseries':\n",
    "        #df=processTimeseriesByDate(root,source,files)\n",
    "        df=processTimeseriesByPixel2(root,source,files)\n",
    "    \n",
    "    if source=='geometry': \n",
    "        df=processGeometry(root,source,files)\n",
    "        df.to_csv(os.path.join(parsedpath,'geometry.csv'))\n",
    "\n",
    "    if source=='masks': \n",
    "        df=processMasks(root,source,files)\n",
    "        df.to_csv(os.path.join(parsedpath,'masks.csv'))\n",
    "\n",
    "    if source=='metadata':\n",
    "        df=processMetadata(root,source,files)\n",
    "        df.to_csv(os.path.join(parsedpath,'metadata.csv'))\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi process \n",
    "\n",
    "#Image visualize function with layers\n",
    "\n",
    "#harvest/unharvested by pixel\n",
    "#size of harvest area attached to pixel\n",
    "\n",
    "#Neighbour cells activity (harvest/not harvest)\n",
    "#Neighbour avg rgb (convolution kernel)\n",
    "#Neighbour cells landforms (rivers,trees,hills,etc)\n",
    "\n",
    "#Distance to landforms,water sources, etc.\n",
    "\n",
    "#Weather,temp,sun,radiation on day?\n",
    "#Soil info?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
